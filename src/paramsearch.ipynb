{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "helloworld\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "print(\"helloworld\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import findspark\n",
    "findspark.init('/Users/jerdavis/devlib/spark-2.4.3-bin-hadoop2.7/')\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars /Users/jerdavis/devlib/xgboost/xgboost4j-spark-0.90.jar,/Users/jerdavis/devlib/xgboost/xgboost4j-0.90.jar,/Users/jerdavis/devhome/projects/pysparkgw/target/scala-2.11/pysparkgw_2.11-0.1.jar pyspark-shell'\n",
    "findspark.init()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder.appName(\"foo\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"8G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2G\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "    # .config(\"spark.driver.extraClassPath\", \"/Users/jerdavis/devlib/xgboost/xgboost4j-spark-0.90.jar:/Users/jerdavis/devlib/xgboost/xgboost4j-0.90.jar:/Users/jerdavis/devhome/projects/pysparkgw/target/scala-2.11/pysparkgw_2.11-0.1.jar\")\\\n",
    "    # .config(\"spark.executor.extraClassPath\", \"/Users/jerdavis/devlib/xgboost/xgboost4j-spark-0.90.jar:/Users/jerdavis/devlib/xgboost/xgboost4j-0.90.jar:/Users/jerdavis/devhome/projects/pysparkgw/target/scala-2.11/pysparkgw_2.11-0.1.jar\")\\\n",
    "    # .config(\"spark.jars\", \"/Users/jerdavis/devlib/xgboost/xgboost4j-spark-0.90.jar:/Users/jerdavis/devlib/xgboost/xgboost4j-0.90.jar:/Users/jerdavis/devhome/projects/pysparkgw/target/scala-2.11/pysparkgw_2.11-0.1.jar\")\\\n",
    "\n",
    "#spark.sparkContext.addPyFile(\"/Users/jerdavis/devlib/xgboost/sparkxgb.zip\")\n",
    "\n",
    "#import sparkxgb\n",
    "#from sparkxgb import XGBoostEstimator\n",
    "\n",
    "\n",
    "# selfHelper = spark.sparkContext._jvm.jd.PyTest\n",
    "# selfHelper.quoteRandallzz()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\n",
      "+-----------+----------+\n|PassengerId|prediction|\n+-----------+----------+\n|        1.0|       0.0|\n|        4.0|       1.0|\n|       14.0|       0.0|\n|       15.0|       1.0|\n|       20.0|       1.0|\n|       28.0|       1.0|\n|       34.0|       0.0|\n|       38.0|       0.0|\n|       50.0|       1.0|\n|       52.0|       0.0|\n|       59.0|       1.0|\n|       60.0|       0.0|\n|       82.0|       0.0|\n|       94.0|       0.0|\n|       96.0|       0.0|\n|       99.0|       1.0|\n|      104.0|       0.0|\n|      105.0|       0.0|\n|      107.0|       1.0|\n|      116.0|       0.0|\n+-----------+----------+\nonly showing top 20 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "selfHelper = spark.sparkContext._jvm.jd.PyTest\n",
    "#selfHelper.foo(123,\"smoo\")\n",
    "print(selfHelper.bar(123,\"smoo\",spark.sparkContext._jsc))\n",
    "\n",
    "rr = spark.sql(\"SELECT * from rr\")\n",
    "rr.show()\n",
    "\n",
    "# schema = StructType(\n",
    "#   [StructField(\"PassengerId\", DoubleType()),\n",
    "#     StructField(\"Survival\", DoubleType()),\n",
    "#     StructField(\"Pclass\", DoubleType()),\n",
    "#     StructField(\"Name\", StringType()),\n",
    "#     StructField(\"Sex\", StringType()),\n",
    "#     StructField(\"Age\", DoubleType()),\n",
    "#     StructField(\"SibSp\", DoubleType()),\n",
    "#     StructField(\"Parch\", DoubleType()),\n",
    "#     StructField(\"Ticket\", StringType()),\n",
    "#     StructField(\"Fare\", DoubleType()),\n",
    "#     StructField(\"Cabin\", StringType()),\n",
    "#     StructField(\"Embarked\", StringType())\n",
    "#   ])\n",
    "# \n",
    "# df_raw = spark\\\n",
    "#   .read\\\n",
    "#   .option(\"header\", \"true\")\\\n",
    "#   .schema(schema)\\\n",
    "#   .csv(\"/Users/jerdavis/devlib/xgboost/train.csv\")\n",
    "# df = df_raw.na.fill(0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "sexIndexer = StringIndexer()\\\n",
    "  .setInputCol(\"Sex\")\\\n",
    "  .setOutputCol(\"SexIndex\")\\\n",
    "  .setHandleInvalid(\"keep\")\n",
    "    \n",
    "cabinIndexer = StringIndexer()\\\n",
    "  .setInputCol(\"Cabin\")\\\n",
    "  .setOutputCol(\"CabinIndex\")\\\n",
    "  .setHandleInvalid(\"keep\")\n",
    "    \n",
    "embarkedIndexer = StringIndexer()\\\n",
    "  .setInputCol(\"Embarked\")\\\n",
    "  .setOutputCol(\"EmbarkedIndex\")\\\n",
    "  .setHandleInvalid(\"keep\")\n",
    "\n",
    "vectorAssembler = VectorAssembler()\\\n",
    "  .setInputCols([\"Pclass\", \"SexIndex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"CabinIndex\", \"EmbarkedIndex\"])\\\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "foo = {\"featuresCol\":\"features\",\"labelCol\":\"Survival\",\"predictionCol\":\"prediction\"}\n",
    "\n",
    "#xgboost = XGBoostEstimator(foo)\n",
    "    # featuresCol=\"features\", \n",
    "    # labelCol=\"Survival\", \n",
    "    # predictionCol=\"prediction\",\n",
    "    # maxDepth=\"20\",\n",
    "\n",
    "\n",
    "# xgboost = XGBoostEstimator(\n",
    "#     featuresCol=\"features\", \n",
    "#     labelCol=\"Survival\", \n",
    "#     predictionCol=\"prediction\")\n",
    "    \n",
    " \n",
    "pipeline = Pipeline().setStages([sexIndexer, cabinIndexer, embarkedIndexer, vectorAssembler, xgboost])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "+-----------+----------+\n|PassengerId|prediction|\n+-----------+----------+\n|        1.0|       0.0|\n|        4.0|       1.0|\n|       14.0|       0.0|\n|       15.0|       1.0|\n|       20.0|       1.0|\n|       28.0|       1.0|\n|       34.0|       0.0|\n|       38.0|       0.0|\n|       50.0|       1.0|\n|       52.0|       0.0|\n|       59.0|       1.0|\n|       60.0|       0.0|\n|       82.0|       0.0|\n|       94.0|       0.0|\n|       96.0|       0.0|\n|       99.0|       1.0|\n|      104.0|       0.0|\n|      105.0|       0.0|\n|      107.0|       1.0|\n|      116.0|       0.0|\n+-----------+----------+\nonly showing top 20 rows\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "trainDF, testDF = df.randomSplit([0.8, 0.2], seed=24)\n",
    "model = pipeline.fit(trainDF)\n",
    "model.transform(testDF).select(col(\"PassengerId\"), col(\"prediction\")).show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\r  0%|          | 0/120 [00:00<?, ?it/s, best loss: ?]",
      "\r  1%|          | 1/120 [00:01<03:23,  1.71s/it, best loss: 0.01153099536895752]",
      "\r  2%|▏         | 2/120 [00:03<03:20,  1.70s/it, best loss: 0.0057669878005981445]",
      "\r  2%|▎         | 3/120 [00:05<03:16,  1.68s/it, best loss: 0.0057669878005981445]",
      "\r  3%|▎         | 4/120 [00:06<03:11,  1.65s/it, best loss: 0.0057669878005981445]",
      "\r  4%|▍         | 5/120 [00:08<03:09,  1.65s/it, best loss: 0.0038160085678100586]",
      "\r  5%|▌         | 6/120 [00:10<03:18,  1.74s/it, best loss: 0.0038160085678100586]",
      "\r  6%|▌         | 7/120 [00:11<03:11,  1.69s/it, best loss: 0.0038160085678100586]",
      "\r  7%|▋         | 8/120 [00:13<03:16,  1.76s/it, best loss: 0.0038160085678100586]",
      "\r  8%|▊         | 9/120 [00:15<03:20,  1.81s/it, best loss: 0.0038160085678100586]",
      "\r  8%|▊         | 10/120 [00:17<03:10,  1.73s/it, best loss: 0.0014569759368896484]",
      "\r  9%|▉         | 11/120 [00:18<03:03,  1.69s/it, best loss: 0.0014569759368896484]",
      "\r 10%|█         | 12/120 [00:20<02:57,  1.64s/it, best loss: 0.0014569759368896484]",
      "\r 11%|█         | 13/120 [00:21<02:50,  1.60s/it, best loss: 0.0014569759368896484]",
      "\r 12%|█▏        | 14/120 [00:23<02:45,  1.56s/it, best loss: 0.0014399886131286621]",
      "\r 12%|█▎        | 15/120 [00:24<02:44,  1.57s/it, best loss: 0.0014399886131286621]",
      "\r 13%|█▎        | 16/120 [00:26<02:44,  1.58s/it, best loss: 0.0014399886131286621]",
      "\r 14%|█▍        | 17/120 [00:28<02:55,  1.70s/it, best loss: 0.0014399886131286621]",
      "\r 15%|█▌        | 18/120 [00:29<02:46,  1.64s/it, best loss: 0.0014399886131286621]",
      "\r 16%|█▌        | 19/120 [00:31<02:43,  1.62s/it, best loss: 0.0014399886131286621]",
      "\r 17%|█▋        | 20/120 [00:33<02:40,  1.61s/it, best loss: 0.0014399886131286621]",
      "\r 18%|█▊        | 21/120 [00:34<02:37,  1.59s/it, best loss: 0.0014399886131286621]",
      "\r 18%|█▊        | 22/120 [00:36<02:33,  1.57s/it, best loss: 0.0014399886131286621]",
      "\r 19%|█▉        | 23/120 [00:37<02:31,  1.56s/it, best loss: 0.0014399886131286621]",
      "\r 20%|██        | 24/120 [00:39<02:34,  1.61s/it, best loss: 0.0014399886131286621]",
      "\r 21%|██        | 25/120 [00:40<02:29,  1.57s/it, best loss: 0.0014399886131286621]",
      "\r 22%|██▏       | 26/120 [00:42<02:28,  1.58s/it, best loss: 0.0014399886131286621]",
      "\r 22%|██▎       | 27/120 [00:44<02:30,  1.62s/it, best loss: 0.0005829930305480957]",
      "\r 23%|██▎       | 28/120 [00:45<02:26,  1.60s/it, best loss: 0.0005829930305480957]",
      "\r 24%|██▍       | 29/120 [00:47<02:24,  1.58s/it, best loss: 0.0005829930305480957]",
      "\r 25%|██▌       | 30/120 [00:48<02:23,  1.60s/it, best loss: 0.0005829930305480957]",
      "\r 26%|██▌       | 31/120 [00:50<02:21,  1.59s/it, best loss: 0.0005829930305480957]",
      "\r 27%|██▋       | 32/120 [00:52<02:18,  1.57s/it, best loss: 0.0005829930305480957]",
      "\r 28%|██▊       | 33/120 [00:53<02:14,  1.54s/it, best loss: 0.0005829930305480957]",
      "\r 28%|██▊       | 34/120 [00:54<02:11,  1.53s/it, best loss: 0.0005829930305480957]",
      "\r 29%|██▉       | 35/120 [00:56<02:08,  1.51s/it, best loss: 0.0005829930305480957]",
      "\r 30%|███       | 36/120 [00:57<02:07,  1.52s/it, best loss: 0.0005829930305480957]",
      "\r 31%|███       | 37/120 [00:59<02:05,  1.52s/it, best loss: 0.0005829930305480957]",
      "\r 32%|███▏      | 38/120 [01:01<02:04,  1.51s/it, best loss: 0.0005829930305480957]",
      "\r 32%|███▎      | 39/120 [01:02<02:03,  1.52s/it, best loss: 0.0005829930305480957]",
      "\r 33%|███▎      | 40/120 [01:04<02:00,  1.51s/it, best loss: 0.0005829930305480957]",
      "\r 34%|███▍      | 41/120 [01:05<01:58,  1.50s/it, best loss: 0.0005829930305480957]",
      "\r 35%|███▌      | 42/120 [01:07<01:58,  1.51s/it, best loss: 0.0005829930305480957]",
      "\r 36%|███▌      | 43/120 [01:08<01:55,  1.50s/it, best loss: 0.0005829930305480957]",
      "\r 37%|███▋      | 44/120 [01:10<01:54,  1.51s/it, best loss: 0.0005829930305480957]",
      "\r 38%|███▊      | 45/120 [01:12<02:06,  1.69s/it, best loss: 0.0005829930305480957]",
      "\r 38%|███▊      | 46/120 [01:13<02:07,  1.73s/it, best loss: 0.0005829930305480957]",
      "\r 39%|███▉      | 47/120 [01:15<02:08,  1.76s/it, best loss: 0.0005829930305480957]",
      "\r 40%|████      | 48/120 [01:17<02:04,  1.73s/it, best loss: 0.0005829930305480957]",
      "\r 41%|████      | 49/120 [01:19<02:01,  1.71s/it, best loss: 0.0005829930305480957]",
      "\r 42%|████▏     | 50/120 [01:20<01:57,  1.68s/it, best loss: 0.0005829930305480957]",
      "\r 42%|████▎     | 51/120 [01:22<01:56,  1.69s/it, best loss: 0.0005829930305480957]",
      "\r 43%|████▎     | 52/120 [01:23<01:51,  1.64s/it, best loss: 0.0005829930305480957]",
      "\r 44%|████▍     | 53/120 [01:25<01:52,  1.68s/it, best loss: 0.0005829930305480957]",
      "\r 45%|████▌     | 54/120 [01:27<01:46,  1.62s/it, best loss: 0.0005829930305480957]",
      "\r 46%|████▌     | 55/120 [01:28<01:42,  1.58s/it, best loss: 0.0005829930305480957]",
      "\r 47%|████▋     | 56/120 [01:30<01:38,  1.54s/it, best loss: 0.0005829930305480957]",
      "\r 48%|████▊     | 57/120 [01:31<01:35,  1.52s/it, best loss: 0.0005829930305480957]",
      "\r 48%|████▊     | 58/120 [01:33<01:34,  1.52s/it, best loss: 0.0005829930305480957]",
      "\r 49%|████▉     | 59/120 [01:34<01:32,  1.51s/it, best loss: 0.0005829930305480957]",
      "\r 50%|█████     | 60/120 [01:36<01:29,  1.50s/it, best loss: 0.0005829930305480957]",
      "\r 51%|█████     | 61/120 [01:37<01:29,  1.51s/it, best loss: 0.0005829930305480957]",
      "\r 52%|█████▏    | 62/120 [01:39<01:27,  1.51s/it, best loss: 0.0005829930305480957]",
      "\r 52%|█████▎    | 63/120 [01:40<01:25,  1.51s/it, best loss: 0.0005829930305480957]",
      "\r 53%|█████▎    | 64/120 [01:42<01:25,  1.52s/it, best loss: 0.0005829930305480957]",
      "\r 54%|█████▍    | 65/120 [01:43<01:23,  1.52s/it, best loss: 0.0005829930305480957]",
      "\r 55%|█████▌    | 66/120 [01:45<01:22,  1.53s/it, best loss: 0.0005829930305480957]",
      "\r 56%|█████▌    | 67/120 [01:47<01:24,  1.59s/it, best loss: 0.0005829930305480957]",
      "\r 57%|█████▋    | 68/120 [01:48<01:24,  1.62s/it, best loss: 0.0005829930305480957]",
      "\r 57%|█████▊    | 69/120 [01:50<01:23,  1.64s/it, best loss: 0.0005829930305480957]",
      "\r 58%|█████▊    | 70/120 [01:52<01:23,  1.68s/it, best loss: 0.0005829930305480957]",
      "\r 59%|█████▉    | 71/120 [01:54<01:31,  1.86s/it, best loss: 0.0005829930305480957]",
      "\r 60%|██████    | 72/120 [01:56<01:24,  1.77s/it, best loss: 0.0005829930305480957]",
      "\r 61%|██████    | 73/120 [01:57<01:19,  1.69s/it, best loss: 0.0005829930305480957]",
      "\r 62%|██████▏   | 74/120 [01:59<01:15,  1.65s/it, best loss: 0.0005829930305480957]",
      "\r 62%|██████▎   | 75/120 [02:00<01:12,  1.61s/it, best loss: 0.0005829930305480957]",
      "\r 63%|██████▎   | 76/120 [02:02<01:12,  1.66s/it, best loss: 0.0005829930305480957]",
      "\r 64%|██████▍   | 77/120 [02:03<01:08,  1.60s/it, best loss: 0.0005829930305480957]",
      "\r 65%|██████▌   | 78/120 [02:05<01:05,  1.57s/it, best loss: 0.0005829930305480957]",
      "\r 66%|██████▌   | 79/120 [02:06<01:04,  1.58s/it, best loss: 0.0005829930305480957]",
      "\r 67%|██████▋   | 80/120 [02:08<01:04,  1.61s/it, best loss: 0.0005829930305480957]",
      "\r 68%|██████▊   | 81/120 [02:10<01:04,  1.64s/it, best loss: 0.0005829930305480957]",
      "\r 68%|██████▊   | 82/120 [02:11<01:02,  1.63s/it, best loss: 0.0005829930305480957]",
      "\r 69%|██████▉   | 83/120 [02:13<01:00,  1.63s/it, best loss: 0.0005829930305480957]",
      "\r 70%|███████   | 84/120 [02:15<00:56,  1.58s/it, best loss: 0.0005829930305480957]",
      "\r 71%|███████   | 85/120 [02:16<00:54,  1.55s/it, best loss: 0.0005829930305480957]",
      "\r 72%|███████▏  | 86/120 [02:18<00:53,  1.57s/it, best loss: 0.0005829930305480957]",
      "\r 72%|███████▎  | 87/120 [02:19<00:53,  1.61s/it, best loss: 0.0005829930305480957]",
      "\r 73%|███████▎  | 88/120 [02:21<00:51,  1.60s/it, best loss: 0.0005829930305480957]",
      "\r 74%|███████▍  | 89/120 [02:23<00:49,  1.60s/it, best loss: 0.0005829930305480957]",
      "\r 75%|███████▌  | 90/120 [02:24<00:47,  1.57s/it, best loss: 0.0005829930305480957]",
      "\r 76%|███████▌  | 91/120 [02:26<00:45,  1.56s/it, best loss: 0.0005829930305480957]",
      "\r 77%|███████▋  | 92/120 [02:27<00:43,  1.56s/it, best loss: 0.0005829930305480957]",
      "\r 78%|███████▊  | 93/120 [02:29<00:42,  1.56s/it, best loss: 0.0005829930305480957]",
      "\r 78%|███████▊  | 94/120 [02:30<00:41,  1.58s/it, best loss: 0.0005829930305480957]",
      "\r 79%|███████▉  | 95/120 [02:32<00:40,  1.60s/it, best loss: 0.0005829930305480957]",
      "\r 80%|████████  | 96/120 [02:34<00:42,  1.76s/it, best loss: 0.0005829930305480957]",
      "\r 81%|████████  | 97/120 [02:36<00:40,  1.75s/it, best loss: 0.0005829930305480957]",
      "\r 82%|████████▏ | 98/120 [02:37<00:36,  1.67s/it, best loss: 0.0005829930305480957]",
      "\r 82%|████████▎ | 99/120 [02:39<00:34,  1.63s/it, best loss: 0.0005829930305480957]",
      "\r 83%|████████▎ | 100/120 [02:40<00:32,  1.63s/it, best loss: 0.0005829930305480957]",
      "\r 84%|████████▍ | 101/120 [02:42<00:30,  1.62s/it, best loss: 0.0005829930305480957]",
      "\r 85%|████████▌ | 102/120 [02:44<00:28,  1.59s/it, best loss: 0.0005829930305480957]",
      "\r 86%|████████▌ | 103/120 [02:45<00:28,  1.65s/it, best loss: 0.0005829930305480957]",
      "\r 87%|████████▋ | 104/120 [02:47<00:27,  1.72s/it, best loss: 0.0005829930305480957]",
      "\r 88%|████████▊ | 105/120 [02:49<00:25,  1.73s/it, best loss: 0.0005829930305480957]",
      "\r 88%|████████▊ | 106/120 [02:50<00:23,  1.66s/it, best loss: 0.00030499696731567383]",
      "\r 89%|████████▉ | 107/120 [02:52<00:20,  1.61s/it, best loss: 0.00030499696731567383]",
      "\r 90%|█████████ | 108/120 [02:54<00:19,  1.59s/it, best loss: 0.00030499696731567383]",
      "\r 91%|█████████ | 109/120 [02:55<00:17,  1.56s/it, best loss: 0.00030499696731567383]",
      "\r 92%|█████████▏| 110/120 [02:56<00:15,  1.53s/it, best loss: 0.00030499696731567383]",
      "\r 92%|█████████▎| 111/120 [02:58<00:13,  1.52s/it, best loss: 0.00030499696731567383]",
      "\r 93%|█████████▎| 112/120 [02:59<00:12,  1.51s/it, best loss: 0.00030499696731567383]",
      "\r 94%|█████████▍| 113/120 [03:01<00:10,  1.51s/it, best loss: 0.00030499696731567383]",
      "\r 95%|█████████▌| 114/120 [03:03<00:09,  1.52s/it, best loss: 0.00030499696731567383]",
      "\r 96%|█████████▌| 115/120 [03:04<00:07,  1.55s/it, best loss: 0.00030499696731567383]",
      "\r 97%|█████████▋| 116/120 [03:06<00:06,  1.54s/it, best loss: 0.00030499696731567383]",
      "\r 98%|█████████▊| 117/120 [03:07<00:04,  1.53s/it, best loss: 0.00030499696731567383]",
      "\r 98%|█████████▊| 118/120 [03:09<00:03,  1.51s/it, best loss: 0.00030499696731567383]",
      "\r 99%|█████████▉| 119/120 [03:10<00:01,  1.50s/it, best loss: 0.00030499696731567383]",
      "\r100%|██████████| 120/120 [03:12<00:00,  1.50s/it, best loss: 0.00030499696731567383]",
      "\n{'eta': 0.9113941275169696, 'foo': 0, 'max_bin': 96.0, 'max_depth': 39.0, 'num_parallel_tree': 4.0}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def train_help(args):\n",
    " \n",
    "   try:\n",
    "      xgbWrapper = spark.sparkContext._jvm.jd.PyTest\n",
    "      \n",
    "      best_score = xgbWrapper.eval(spark.sparkContext._jsc,\n",
    "                                   '/Users/jerdavis/devlib/xgboost/train.csv', \n",
    "                                   [\"Pclass\", \"SexIndex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"CabinIndex\", \"EmbarkedIndex\"],\n",
    "                                   'Survival',\n",
    "                                   float(args['params']['eta']), \n",
    "                                   float(args['params']['gamma']),\n",
    "                                   int(args['params']['max_depth']),\n",
    "                                   int(args['params']['max_leaves']),\n",
    "                                   float(args['params']['min_child_weight']),\n",
    "                                   float(args['params']['subsample']),\n",
    "                                   float(args['params']['colsample_bytree']),\n",
    "                                   float(args['params']['colsample_bylevel']),\n",
    "                                   float(args['params']['colsample_bynode']),\n",
    "                                   float(args['params']['lambda']),\n",
    "                                   float(args['params']['alpha']),\n",
    "                                   int(args['params']['max_bin']),\n",
    "                                   int(args['params']['num_parallel_tree']),\n",
    "                                   int(args['params']['num_round']),\n",
    "                                   int(args['params']['num_early_stopping_rounds']))\n",
    "\n",
    "      \n",
    "      return 1.0 - best_score\n",
    "   except Exception as e:\n",
    "       print(str(e))\n",
    "       return float(1)\n",
    " \n",
    "\n",
    "from hyperopt import tpe, hp, fmin, Trials\n",
    "\n",
    "param_space = hp.choice( 'foo', [{'model':'foom', 'params': {'eta':hp.uniform('eta', 0, 1),\n",
    "                                                             'gamma':1.0,\n",
    "                                                             'max_depth':hp.quniform('max_depth', 3, 60, 3),\n",
    "                                                             'max_leaves':0,\n",
    "                                                             'min_child_weight':1.0,\n",
    "                                                             'subsample':1.0,\n",
    "                                                             'colsample_bytree':1.0,\n",
    "                                                             'colsample_bylevel':1.0,\n",
    "                                                             'colsample_bynode':1.0,\n",
    "                                                             'lambda':1.0,\n",
    "                                                             'alpha':0.0,\n",
    "                                                             'max_bin':hp.quniform('max_bin', 32, 512, 32),\n",
    "                                                             'num_parallel_tree':hp.quniform('num_parallel_tree', 2, 60, 2),\n",
    "                                                             'num_round':100,\n",
    "                                                             'num_early_stopping_rounds':10,\n",
    "                                                             }}])\n",
    "\n",
    "trials = Trials()\n",
    "best_params = fmin( fn=train_help, space = param_space, algo=tpe.suggest, max_evals = 120, trials = trials)\n",
    "print(best_params)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\r  0%|          | 0/5 [00:00<?, ?it/s, best loss: ?]",
      "\r 20%|██        | 1/5 [00:01<00:07,  1.89s/it, best loss: 0.0015929937362670898]",
      "\r 40%|████      | 2/5 [00:03<00:05,  1.81s/it, best loss: 0.0015929937362670898]",
      "\r 60%|██████    | 3/5 [00:05<00:03,  1.72s/it, best loss: 0.0010610222816467285]",
      "\r 80%|████████  | 4/5 [00:06<00:01,  1.66s/it, best loss: 0.0010610222816467285]",
      "\r100%|██████████| 5/5 [00:08<00:00,  1.60s/it, best loss: 0.0010610222816467285]",
      "\nBest: {'eta': 0.9839068958201556, 'foo': 0, 'max_bin': 224.0, 'max_depth': 45.0, 'num_parallel_tree': 14.0}\nFound saved Trials! Loading...\nRerunning from 5 trials to 8 (+3) trials\n\r  0%|          | 0/3 [00:00<?, ?it/s, best loss: ?]",
      "\r 33%|███▎      | 1/3 [00:01<00:03,  1.53s/it, best loss: 0.0010610222816467285]",
      "\r 67%|██████▋   | 2/3 [00:03<00:01,  1.52s/it, best loss: 0.0010610222816467285]",
      "\r100%|██████████| 3/3 [00:04<00:00,  1.51s/it, best loss: 0.0010610222816467285]",
      "\nBest: {'eta': 0.9839068958201556, 'foo': 0, 'max_bin': 224.0, 'max_depth': 45.0, 'num_parallel_tree': 14.0}\nFound saved Trials! Loading...\nRerunning from 8 trials to 11 (+3) trials\n\r  0%|          | 0/3 [00:00<?, ?it/s, best loss: ?]",
      "\r 33%|███▎      | 1/3 [00:01<00:03,  1.60s/it, best loss: 0.0010610222816467285]",
      "\r 67%|██████▋   | 2/3 [00:03<00:01,  1.58s/it, best loss: 0.0010610222816467285]",
      "\r100%|██████████| 3/3 [00:04<00:00,  1.55s/it, best loss: 0.0010610222816467285]",
      "\nBest: {'eta': 0.9839068958201556, 'foo': 0, 'max_bin': 224.0, 'max_depth': 45.0, 'num_parallel_tree': 14.0}\nFound saved Trials! Loading...\nRerunning from 11 trials to 14 (+3) trials\n\r  0%|          | 0/3 [00:00<?, ?it/s, best loss: ?]",
      "\r 33%|███▎      | 1/3 [00:01<00:02,  1.46s/it, best loss: 0.0010610222816467285]",
      "\r 67%|██████▋   | 2/3 [00:03<00:01,  1.60s/it, best loss: 0.0010610222816467285]",
      "\r100%|██████████| 3/3 [00:05<00:00,  1.64s/it, best loss: 0.0010610222816467285]",
      "\nBest: {'eta': 0.9839068958201556, 'foo': 0, 'max_bin': 224.0, 'max_depth': 45.0, 'num_parallel_tree': 14.0}\nFound saved Trials! Loading...\nRerunning from 14 trials to 17 (+3) trials\n\r  0%|          | 0/3 [00:00<?, ?it/s, best loss: ?]",
      "\r 33%|███▎      | 1/3 [00:01<00:03,  1.88s/it, best loss: 0.0010610222816467285]",
      "\r 67%|██████▋   | 2/3 [00:03<00:01,  1.84s/it, best loss: 0.0010610222816467285]",
      "\r100%|██████████| 3/3 [00:05<00:00,  1.78s/it, best loss: 0.0010610222816467285]",
      "\nBest: {'eta': 0.9839068958201556, 'foo': 0, 'max_bin': 224.0, 'max_depth': 45.0, 'num_parallel_tree': 14.0}\nFound saved Trials! Loading...\nRerunning from 17 trials to 20 (+3) trials\n\r  0%|          | 0/3 [00:00<?, ?it/s, best loss: ?]",
      "\r 33%|███▎      | 1/3 [00:01<00:03,  1.89s/it, best loss: 0.0010610222816467285]",
      "\r 67%|██████▋   | 2/3 [00:03<00:01,  1.92s/it, best loss: 0.0010610222816467285]",
      "\r100%|██████████| 3/3 [00:05<00:00,  1.88s/it, best loss: 0.0010610222816467285]",
      "\nBest: {'eta': 0.9839068958201556, 'foo': 0, 'max_bin': 224.0, 'max_depth': 45.0, 'num_parallel_tree': 14.0}\nFound saved Trials! Loading...\nRerunning from 20 trials to 23 (+3) trials\n\r  0%|          | 0/3 [00:00<?, ?it/s, best loss: ?]",
      "\r 33%|███▎      | 1/3 [00:02<00:04,  2.03s/it, best loss: 0.0010610222816467285]",
      "\r 67%|██████▋   | 2/3 [00:03<00:02,  2.00s/it, best loss: 0.0010610222816467285]",
      "\r100%|██████████| 3/3 [00:05<00:00,  2.00s/it, best loss: 0.0010610222816467285]",
      "\nBest: {'eta': 0.9839068958201556, 'foo': 0, 'max_bin': 224.0, 'max_depth': 45.0, 'num_parallel_tree': 14.0}\nFound saved Trials! Loading...\nRerunning from 23 trials to 26 (+3) trials\n\r  0%|          | 0/3 [00:00<?, ?it/s, best loss: ?]",
      "\r 33%|███▎      | 1/3 [00:01<00:03,  1.88s/it, best loss: 0.0010610222816467285]",
      "\r 67%|██████▋   | 2/3 [00:03<00:01,  1.81s/it, best loss: 0.0010610222816467285]",
      "\r100%|██████████| 3/3 [00:05<00:00,  1.83s/it, best loss: 0.0010610222816467285]",
      "\nBest: {'eta': 0.9839068958201556, 'foo': 0, 'max_bin': 224.0, 'max_depth': 45.0, 'num_parallel_tree': 14.0}\nFound saved Trials! Loading...\nRerunning from 26 trials to 29 (+3) trials\n",
      "\r  0%|          | 0/3 [00:00<?, ?it/s, best loss: ?]",
      "\r 33%|███▎      | 1/3 [00:01<00:03,  1.76s/it, best loss: 0.0010610222816467285]",
      "\r 67%|██████▋   | 2/3 [00:03<00:01,  1.76s/it, best loss: 0.0010610222816467285]",
      "\r100%|██████████| 3/3 [00:04<00:00,  1.67s/it, best loss: 0.0010610222816467285]",
      "\nBest: {'eta': 0.9839068958201556, 'foo': 0, 'max_bin': 224.0, 'max_depth': 45.0, 'num_parallel_tree': 14.0}\nFound saved Trials! Loading...\nRerunning from 29 trials to 32 (+3) trials\n\r  0%|          | 0/3 [00:00<?, ?it/s, best loss: ?]",
      "\r 33%|███▎      | 1/3 [00:01<00:03,  1.56s/it, best loss: 0.0010610222816467285]",
      "\r 67%|██████▋   | 2/3 [00:03<00:01,  1.56s/it, best loss: 0.0010610222816467285]",
      "\r100%|██████████| 3/3 [00:04<00:00,  1.58s/it, best loss: 0.0010610222816467285]",
      "\nBest: {'eta': 0.9839068958201556, 'foo': 0, 'max_bin': 224.0, 'max_depth': 45.0, 'num_parallel_tree': 14.0}\nFound saved Trials! Loading...\nRerunning from 32 trials to 35 (+3) trials\n\r  0%|          | 0/3 [00:00<?, ?it/s, best loss: ?]",
      "\r 33%|███▎      | 1/3 [00:01<00:03,  1.63s/it, best loss: 0.0010610222816467285]",
      "\r 67%|██████▋   | 2/3 [00:03<00:01,  1.61s/it, best loss: 0.0010610222816467285]",
      "\r100%|██████████| 3/3 [00:04<00:00,  1.63s/it, best loss: 0.0010610222816467285]",
      "\nBest: {'eta': 0.9839068958201556, 'foo': 0, 'max_bin': 224.0, 'max_depth': 45.0, 'num_parallel_tree': 14.0}\nFound saved Trials! Loading...\nRerunning from 35 trials to 38 (+3) trials\n\r  0%|          | 0/3 [00:00<?, ?it/s, best loss: ?]"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pickle\n",
    "from hyperopt import tpe, hp, fmin, Trials\n",
    "param_space = hp.choice( 'foo', [{'model':'foom', 'params': {'eta':hp.uniform('eta', 0, 1),\n",
    "                                                             'gamma':1.0,\n",
    "                                                             'max_depth':hp.quniform('max_depth', 3, 60, 3),\n",
    "                                                             'max_leaves':0,\n",
    "                                                             'min_child_weight':1.0,\n",
    "                                                             'subsample':1.0,\n",
    "                                                             'colsample_bytree':1.0,\n",
    "                                                             'colsample_bylevel':1.0,\n",
    "                                                             'colsample_bynode':1.0,\n",
    "                                                             'lambda':1.0,\n",
    "                                                             'alpha':0.0,\n",
    "                                                             'max_bin':hp.quniform('max_bin', 32, 512, 32),\n",
    "                                                             'num_parallel_tree':hp.quniform('num_parallel_tree', 2, 60, 2),\n",
    "                                                             'num_round':100,\n",
    "                                                             'num_early_stopping_rounds':10,\n",
    "                                                             }}])\n",
    "\n",
    "\n",
    "def run_trials():\n",
    "\n",
    "    trials_step = 1  # how many additional trials to do after loading saved trials. 1 = save after iteration\n",
    "    max_trials = 2  # initial max_trials. put something small to not have to wait\n",
    "\n",
    "    \n",
    "    try:  # try to load an already saved trials object, and increase the max\n",
    "        trials = pickle.load(open(\"/tmp/my_model.hyperopt\", \"rb\"))\n",
    "        print(\"Found saved Trials! Loading...\")\n",
    "        max_trials = len(trials.trials) + trials_step\n",
    "        print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, trials_step))\n",
    "    except:  # create a new trials object and start searching\n",
    "        trials = Trials()\n",
    "\n",
    "    #best = fmin(fn=mymodel, space=model_space, algo=tpe.suggest, max_evals=max_trials, trials=trials)\n",
    "    best_params = fmin( fn=train_help, space = param_space, algo=tpe.suggest, max_evals=max_trials, trials = trials)\n",
    "\n",
    "    print(\"Best:\", best_params)\n",
    "    \n",
    "    # save the trials object\n",
    "    with open(\"/tmp/my_model.hyperopt\", \"wb\") as f:\n",
    "        pickle.dump(trials, f)\n",
    "\n",
    "# loop indefinitely and stop whenever you like\n",
    "while True:\n",
    "    run_trials()\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}